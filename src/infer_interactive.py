import torch
import torch.nn as nn
import numpy as np
import os
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pandas as pd
from skimage.metrics import structural_similarity as ssim

WINDOW_SIZE = 512
ANOMALY_THRESHOLD = 0.02  # —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥

class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(WINDOW_SIZE, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 16),
        )
        self.decoder = nn.Sequential(
            nn.Linear(16, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, WINDOW_SIZE),
        )

    def forward(self, x):
        return self.decoder(self.encoder(x))


def plot_comparison(original, reconstructed, anomalies, title, save_path):
    plt.figure(figsize=(12, 4))
    plt.plot(original, label="–û—Ä–∏–≥–∏–Ω–∞–ª", alpha=0.6)
    plt.plot(reconstructed, label="–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π", linewidth=1.5)
    if anomalies.any():
        plt.scatter(np.where(anomalies)[0], original[anomalies],
                    color="red", label="–ê–Ω–æ–º–∞–ª–∏–∏", s=20)
    plt.title(title)
    plt.xlabel("–ò–Ω–¥–µ–∫—Å")
    plt.ylabel("–ê–º–ø–ª–∏—Ç—É–¥–∞")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()


def infer_on_file(model, file_path, save_dir, log_path):
    signal = np.load(file_path)
    if len(signal) < WINDOW_SIZE:
        print("‚ö† –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π!")
        return

    orig = signal[:WINDOW_SIZE]
    x = torch.tensor(orig, dtype=torch.float32).unsqueeze(0)
    with torch.no_grad():
        rec = model(x).squeeze().numpy()

    mse = np.mean((orig - rec) ** 2)
    dr = orig.max() - orig.min()
    sim = ssim(orig, rec, data_range=dr)

    diffs = np.abs(orig - rec)

    # 1) —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥
    anoms_fix = diffs > ANOMALY_THRESHOLD
    # 2) –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥: mean + 2*std
    thr_dyn = diffs.mean() + 2 * diffs.std()
    anoms_dyn = diffs > thr_dyn
    # 3) percentile-–ø–æ—Ä–æ–≥ (95%)
    thr_pct = np.percentile(diffs, 95)
    anoms_pct = diffs > thr_pct

    filename = os.path.splitext(os.path.basename(file_path))[0]

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –æ—à–∏–±–æ–∫
    hist_path = os.path.join(save_dir, f"{filename}_error_hist.png")
    plt.figure(figsize=(6, 4))
    plt.hist(diffs, bins=50, alpha=0.7)
    plt.axvline(ANOMALY_THRESHOLD, color='r', linestyle='--',
                label=f'fix {ANOMALY_THRESHOLD:.3f}')
    plt.axvline(thr_dyn, color='g', linestyle='--',
                label=f'dyn {thr_dyn:.3f}')
    plt.axvline(thr_pct, color='b', linestyle='--',
                label=f'95% {thr_pct:.3f}')
    plt.legend()
    plt.xlabel('–û—à–∏–±–∫–∞ |–æ—Ä–∏–≥–∏–Ω–∞–ª ‚Äì –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ|')
    plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    plt.tight_layout()
    plt.savefig(hist_path)
    plt.close()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (—Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –ø–æ—Ä–æ–≥–æ–º)
    recon_path = os.path.join(save_dir, f"{filename}_reconstructed.png")
    title = f"{filename}\nMSE={mse:.6f}, SSIM={sim:.4f}"
    plot_comparison(orig, rec, anoms_dyn, title, recon_path)

    # –õ–æ–≥ –≤ CSV
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    row = pd.DataFrame([{
        "file": filename,
        "mse": mse,
        "ssim": sim,
        "anom_fix": int(anoms_fix.sum()),
        "anom_dyn": int(anoms_dyn.sum()),
        "anom_pct": int(anoms_pct.sum())
    }])
    if os.path.exists(log_path):
        row.to_csv(log_path, mode="a", header=False, index=False)
    else:
        row.to_csv(log_path, index=False)

    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
    print(f"\n‚úÖ {filename}: MSE={mse:.6f}, SSIM={sim:.4f}")
    print(f" –ê–Ω–æ–º–∞–ª–∏–π fix/dyn/pct: {anoms_fix.sum()}/{anoms_dyn.sum()}/{anoms_pct.sum()}")
    print(f"üìä –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {os.path.basename(hist_path)}")
    print(f"üì∏ –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {os.path.basename(recon_path)}")


if __name__ == "__main__":
    root       = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    model_path = os.path.join(root, "models", "autoencoder_synthetic.pth")
    save_dir   = os.path.join(root, "data", "inference_samples")
    log_path   = os.path.join(save_dir, "inference_samples_log.csv")
    os.makedirs(save_dir, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = Autoencoder()
    model.load_state_dict(torch.load(model_path, map_location="cpu"))
    model.eval()

    data_dir = os.path.join(root, "data")
    while True:
        # 1) –°–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫
        dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
        print("\nüìÅ –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞–ø–∫–∏:")
        for i, d in enumerate(dirs, 1):
            print(f"{i}. {d}")

        try:
            d_idx = int(input("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –ø–∞–ø–∫–∏ (0 ‚Äî –≤—ã—Ö–æ–¥): "))
            if d_idx == 0:
                break
            target_dir = os.path.join(data_dir, dirs[d_idx-1])
        except:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            continue

        # 2) –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ .npy –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ
        files = [f for f in os.listdir(target_dir) if f.endswith(".npy")]
        if not files:
            print("‚ùå –í –ø–∞–ø–∫–µ –Ω–µ—Ç .npy —Ñ–∞–π–ª–æ–≤.")
            continue

        print(f"\nüìÇ –§–∞–π–ª—ã –≤ ¬´{dirs[d_idx-1]}¬ª:")
        for i, f in enumerate(files, 1):
            print(f"{i}. {f}")

        try:
            f_idx = int(input("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞ (0 ‚Äî –≤—ã–±—Ä–∞—Ç—å –ø–∞–ø–∫—É): "))
            if f_idx == 0:
                continue
            file_path = os.path.join(target_dir, files[f_idx-1])
        except:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            continue

        # 3) –ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        infer_on_file(model, file_path, save_dir, log_path)
